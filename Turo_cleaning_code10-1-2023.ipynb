{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5a6923-dfc5-4bc1-b2ee-69ec4aa88f41",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1>Turo Data Cleaning Notebook</h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "## This notebook processes raw data scraped from the Turo website, cleaning and truncating it to prepare a clean dataset ready for analysis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac588227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09743097",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The raw data that was scraped from the Turo website is stored in 13 csv files inside a single folder.  I want to create a list containing the file paths for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "134d1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week15.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week0.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week2.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week4.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week6.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week7.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week8.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week9.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week10.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week11.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week12.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week13.csv',\n",
       " 'F:\\\\Data Scraping\\\\Turo\\\\Nashville\\\\Octorber\\\\Raw Excel\\\\week14.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a variable that contains the folder path\n",
    "folder_path = r\"F:\\Data Scraping\\Turo\\Nashville\\Octorber\\Raw Excel\"\n",
    "\n",
    "# Innitiate an empty list to store the csv file paths\n",
    "file_paths = []\n",
    "\n",
    "# Iterate over all items in the specified folder path.\n",
    "# If the item is a file, add it to the list 'folder_path'\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "# View the list of file paths\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1797d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Concatenate all files together into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5670a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicles.id</th>\n",
       "      <th>vehicles.completedTrips</th>\n",
       "      <th>vehicles.estimatedQuote</th>\n",
       "      <th>vehicles.hostId</th>\n",
       "      <th>vehicles.isAllStarHost</th>\n",
       "      <th>vehicles.isFavoritedBySearcher</th>\n",
       "      <th>vehicles.isNewListing</th>\n",
       "      <th>vehicles.make</th>\n",
       "      <th>vehicles.model</th>\n",
       "      <th>vehicles.rating</th>\n",
       "      <th>...</th>\n",
       "      <th>searchLocation.appliedRadius.unit</th>\n",
       "      <th>searchLocation.appliedRadius.value</th>\n",
       "      <th>searchLocation.point.lat</th>\n",
       "      <th>searchLocation.point.lng</th>\n",
       "      <th>searchLocation.topPois[0].name</th>\n",
       "      <th>searchLocation.topPois[0].locationId</th>\n",
       "      <th>searchLocation.topPois[0].shortName</th>\n",
       "      <th>searchLocation.topPois[0].type</th>\n",
       "      <th>searchLocation.topPois[0].point.lat</th>\n",
       "      <th>searchLocation.topPois[0].point.lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2190039</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24710785</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Taos</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MILES</td>\n",
       "      <td>6.430942</td>\n",
       "      <td>36.180583</td>\n",
       "      <td>-86.804193</td>\n",
       "      <td>Music City Star Riverfront Station</td>\n",
       "      <td>8558547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAIN_STATION</td>\n",
       "      <td>36.16214</td>\n",
       "      <td>-86.7738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2182884</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24710785</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Tiguan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MILES</td>\n",
       "      <td>6.430942</td>\n",
       "      <td>36.180583</td>\n",
       "      <td>-86.804193</td>\n",
       "      <td>Music City Star Riverfront Station</td>\n",
       "      <td>8558547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAIN_STATION</td>\n",
       "      <td>36.16214</td>\n",
       "      <td>-86.7738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2181949</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6333177</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>GL-Class</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MILES</td>\n",
       "      <td>6.430942</td>\n",
       "      <td>36.180583</td>\n",
       "      <td>-86.804193</td>\n",
       "      <td>Music City Star Riverfront Station</td>\n",
       "      <td>8558547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAIN_STATION</td>\n",
       "      <td>36.16214</td>\n",
       "      <td>-86.7738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2160753</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5849654</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Jetta</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MILES</td>\n",
       "      <td>6.430942</td>\n",
       "      <td>36.180583</td>\n",
       "      <td>-86.804193</td>\n",
       "      <td>Music City Star Riverfront Station</td>\n",
       "      <td>8558547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAIN_STATION</td>\n",
       "      <td>36.16214</td>\n",
       "      <td>-86.7738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2099638</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24710785</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MILES</td>\n",
       "      <td>6.430942</td>\n",
       "      <td>36.180583</td>\n",
       "      <td>-86.804193</td>\n",
       "      <td>Music City Star Riverfront Station</td>\n",
       "      <td>8558547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAIN_STATION</td>\n",
       "      <td>36.16214</td>\n",
       "      <td>-86.7738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   vehicles.id  vehicles.completedTrips  vehicles.estimatedQuote  \\\n",
       "0      2190039                       10                      NaN   \n",
       "1      2182884                        6                      NaN   \n",
       "2      2181949                       10                      NaN   \n",
       "3      2160753                       12                      NaN   \n",
       "4      2099638                       19                      NaN   \n",
       "\n",
       "   vehicles.hostId  vehicles.isAllStarHost  vehicles.isFavoritedBySearcher  \\\n",
       "0         24710785                   False                           False   \n",
       "1         24710785                   False                           False   \n",
       "2          6333177                   False                           False   \n",
       "3          5849654                   False                           False   \n",
       "4         24710785                   False                           False   \n",
       "\n",
       "   vehicles.isNewListing  vehicles.make vehicles.model  vehicles.rating  ...  \\\n",
       "0                  False     Volkswagen           Taos              5.0  ...   \n",
       "1                  False     Volkswagen         Tiguan              5.0  ...   \n",
       "2                  False  Mercedes-Benz       GL-Class              5.0  ...   \n",
       "3                  False     Volkswagen          Jetta              5.0  ...   \n",
       "4                  False      Chevrolet       Suburban              5.0  ...   \n",
       "\n",
       "  searchLocation.appliedRadius.unit  searchLocation.appliedRadius.value  \\\n",
       "0                             MILES                            6.430942   \n",
       "1                             MILES                            6.430942   \n",
       "2                             MILES                            6.430942   \n",
       "3                             MILES                            6.430942   \n",
       "4                             MILES                            6.430942   \n",
       "\n",
       "   searchLocation.point.lat searchLocation.point.lng  \\\n",
       "0                 36.180583               -86.804193   \n",
       "1                 36.180583               -86.804193   \n",
       "2                 36.180583               -86.804193   \n",
       "3                 36.180583               -86.804193   \n",
       "4                 36.180583               -86.804193   \n",
       "\n",
       "       searchLocation.topPois[0].name searchLocation.topPois[0].locationId  \\\n",
       "0  Music City Star Riverfront Station                            8558547.0   \n",
       "1  Music City Star Riverfront Station                            8558547.0   \n",
       "2  Music City Star Riverfront Station                            8558547.0   \n",
       "3  Music City Star Riverfront Station                            8558547.0   \n",
       "4  Music City Star Riverfront Station                            8558547.0   \n",
       "\n",
       "   searchLocation.topPois[0].shortName  searchLocation.topPois[0].type  \\\n",
       "0                                  NaN                   TRAIN_STATION   \n",
       "1                                  NaN                   TRAIN_STATION   \n",
       "2                                  NaN                   TRAIN_STATION   \n",
       "3                                  NaN                   TRAIN_STATION   \n",
       "4                                  NaN                   TRAIN_STATION   \n",
       "\n",
       "  searchLocation.topPois[0].point.lat searchLocation.topPois[0].point.lng  \n",
       "0                            36.16214                            -86.7738  \n",
       "1                            36.16214                            -86.7738  \n",
       "2                            36.16214                            -86.7738  \n",
       "3                            36.16214                            -86.7738  \n",
       "4                            36.16214                            -86.7738  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Innitiate an empty list to store the data frames\n",
    "cars_dfs = []\n",
    "\n",
    "# Read in each data frame and store it in the list\n",
    "for df in file_paths: \n",
    "    df = pd.read_csv(df)\n",
    "    cars_dfs.append(df)\n",
    "\n",
    "# Concatenate the data frames together\n",
    "concat_df = pd.concat(cars_dfs)\n",
    "\n",
    "# view the data frame\n",
    "concat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b16e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Innitial Cleaning\n",
    "\n",
    "1. Truncate the columns of the data frame.\n",
    "2. Rename the columns.\n",
    "3. Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50e8c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4948 rows in this data frame\n",
      "There are 1038 unique vehicles in the dataset\n",
      "The dataset contains 3910 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Sub-set only the columns of interest\n",
    "concat_df = concat_df[['vehicles.id', \n",
    "                      'vehicles.completedTrips',\n",
    "                      'vehicles.hostId',\n",
    "                      'vehicles.isAllStarHost',\n",
    "                      'vehicles.isFavoritedBySearcher', \n",
    "                      'vehicles.isNewListing',\n",
    "                      'vehicles.make',\n",
    "                      'vehicles.model',\n",
    "                      'vehicles.rating',\n",
    "                      'vehicles.type',\n",
    "                      'vehicles.year',\n",
    "                      'vehicles.avgDailyPrice.amount',\n",
    "                      'vehicles.location.city',\n",
    "                      'vehicles.location.homeLocation.lat',\n",
    "                      'vehicles.location.homeLocation.lng']]\n",
    "\n",
    "# Create a dictionary of new column names\n",
    "new_column_names = {'vehicles.id':'id', \n",
    "                      'vehicles.completedTrips':'trips_oct2023',\n",
    "                      'vehicles.hostId':'host_id_oct2023',\n",
    "                      'vehicles.isAllStarHost':'all_star_host_oct2023',\n",
    "                      'vehicles.isFavoritedBySearcher':'favorited_by_searcher_oct2023', \n",
    "                      'vehicles.isNewListing':'new_listing_oct2023',\n",
    "                      'vehicles.make':'make_oct2023',\n",
    "                      'vehicles.model':'model_oct2023',\n",
    "                      'vehicles.rating':'rating_oct2023',\n",
    "                      'vehicles.type':'type_oct2023',\n",
    "                      'vehicles.year':'year_oct2023',\n",
    "                      'vehicles.avgDailyPrice.amount':'price_per_day_oct2023',\n",
    "                      'vehicles.location.city':'city_oct2023',\n",
    "                      'vehicles.location.homeLocation.lat':'lat_oct2023',\n",
    "                      'vehicles.location.homeLocation.lng':'lng_oct2023'}\n",
    "\n",
    "# Apply new column names to df\n",
    "new_df = concat_df.rename(columns=new_column_names)\n",
    "\n",
    "# drop duplicates\n",
    "unique_data = new_df.drop_duplicates()\n",
    "\n",
    "# Print the count of rows and columns for the data frame\n",
    "df_rows = unique_data.shape[0]\n",
    "print(f\"There are {df_rows} rows in this data frame\")\n",
    "\n",
    "# Print the number of unique ids in the data frame\n",
    "unique_vehicles = unique_data[['id']].drop_duplicates().shape[0]\n",
    "print(f\"There are {unique_vehicles} unique vehicles in the dataset\")\n",
    "\n",
    "# print count of duplicates still contained in the dataset\n",
    "print(f\"The dataset contains {df_rows-unique_vehicles} duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe039a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### After dropping duplicates on the id column, the data frame still has some duplicate values\n",
    "\n",
    "#### Because of the way the data was scraped, there are some fields that hold different values for the same vehicles:\n",
    "\n",
    "1. **Price Per Day**\n",
    "   * Hosts often give renters a discount for booking a vehicle several weeks in advance.  Therefore, the rental price of the vehicle may vary depending on how far in advance it is booked.  This data includes the rental price for a given vehicle ranging from one week in advance to 15 weeks in advance. I want to find the *average* rental price for each vehicle.\n",
    "3. **Rating**\n",
    "   * Because the scrapping of this data took about five hours, some renters ended their trip and provided a rating for their trip during the data scraping process.  Therefore, the same vehicle could have multiple values for the â€˜Ratingâ€™ field. I want to find the *average* rating for each vehicle.\n",
    "5. **Trips**\n",
    "   * Because the scrapping of this data took about five hours, some renters ended their trip during the data scraping process.  Therefore, the same vehicle could have multiple values for the â€˜Tripâ€™ field. I want to find the *greatest* trip value for each vehicle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d88173-717e-4ec1-a3eb-8fb0541652ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Average price per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5c1973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 1093 rows in this data frame\n",
      "There are 1038 unique vehicles in the dataset\n",
      "The dataset contains 55 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Group by id and return a df with averge price for each id\n",
    "join1 = unique_data.groupby('id')['price_per_day_oct2023'].agg(average_price='mean').reset_index()\n",
    "\n",
    "# Remove the price column from the original df and drop the duplicates\n",
    "join2 = unique_data.drop(columns = ['price_per_day_oct2023']).drop_duplicates()\n",
    "\n",
    "#Join the average price df to the original df\n",
    "final_clean = pd.merge(join1, join2, how = 'inner', on = 'id')\n",
    "\n",
    "# rename the column\n",
    "final_clean = final_clean.rename(columns = {'average_price' : 'average_price_oct2023'})\n",
    "\n",
    "# Print the count of rows and columns for the data frame\n",
    "df_rows = final_clean.shape[0]\n",
    "print(f\"There are now {df_rows} rows in this data frame\")\n",
    "\n",
    "# Print the number of unique ids in the data frame\n",
    "print(f\"There are {unique_vehicles} unique vehicles in the dataset\")\n",
    "\n",
    "# print count of duplicates still contained in the dataset\n",
    "print(f\"The dataset contains {df_rows-unique_vehicles} duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39179243",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96874392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 1082 rows in this data frame\n",
      "There are 1038 unique vehicles in the dataset\n",
      "The dataset contains 44 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Group by id and return a df with averge trip rating for each id\n",
    "join1 = final_clean.groupby('id')['rating_oct2023'].agg(average_rating='mean').reset_index()\n",
    "\n",
    "# Remove the rating column from the original df and drop the duplicates\n",
    "join2 = final_clean.drop(columns = ['rating_oct2023']).drop_duplicates()\n",
    "\n",
    "# Join the average rating df to the original df\n",
    "final_clean = pd.merge(join1, join2, how = 'inner', on = 'id')\n",
    "\n",
    "# Rename the column\n",
    "final_clean = final_clean.rename(columns = {'average_rating' : 'average_rating_oct2023'})\n",
    "\n",
    "# Print the count of rows and columns for the data frame\n",
    "df_rows = final_clean.shape[0]\n",
    "print(f\"There are now {df_rows} rows in this data frame\")\n",
    "\n",
    "# Print the number of unique ids in the data frame\n",
    "print(f\"There are {unique_vehicles} unique vehicles in the dataset\")\n",
    "\n",
    "# print count of duplicates still contained in the dataset\n",
    "print(f\"The dataset contains {df_rows-unique_vehicles} duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054acce9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "If one car has two different values for 'trips', then take the larger one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d4f428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 1038 rows in this data frame\n",
      "There are 1038 unique vehicles in the dataset\n",
      "The dataset contains 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Group by id and return a df with max trips for each id\n",
    "join1 = final_clean.groupby('id')['trips_oct2023'].max().reset_index()\n",
    "\n",
    "# Remove the trips column from the original df and drop the duplicates\n",
    "join2 = final_clean.drop(columns = ['trips_oct2023']).drop_duplicates()\n",
    "\n",
    "# Join the trips df to the original df\n",
    "final_clean = pd.merge(join1, join2, how = 'inner', on = 'id')\n",
    "\n",
    "# rename the column\n",
    "final_clean = final_clean.rename(columns = {'trips' : 'trips_oct2023'})\n",
    "\n",
    "# Print the count of rows and columns for the data frame\n",
    "df_rows = final_clean.shape[0]\n",
    "print(f\"There are now {df_rows} rows in this data frame\")\n",
    "\n",
    "# Print the number of unique ids in the data frame\n",
    "print(f\"There are {unique_vehicles} unique vehicles in the dataset\")\n",
    "\n",
    "# print count of duplicates still contained in the dataset\n",
    "print(f\"The dataset contains {df_rows-unique_vehicles} duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8caa8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Cleaning city names\n",
    "\n",
    "1. Keep only the cities that are close to Nashville\n",
    "2. Fix redundancies and change improperly names cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0543b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nashville', 'Brentwood', 'Aurora', 'Murfreesboro',\n",
       "       'Hendersonville', 'Franklin', 'Smyrna', 'Greenbrier',\n",
       "       'Spring Hill', 'Gallatin', 'Goodlettsville', 'Lebanon',\n",
       "       'Hermitage', 'Christiana', 'Antioch', 'Mt. Juliet', 'Lascassas',\n",
       "       'La Vergne', 'Mount Juliet', 'Columbia', 'Forest Hills',\n",
       "       \"Thompson's Station\", 'Nolensville', 'Arrington', 'White House',\n",
       "       'Beechgrove', 'Clarksville', 'Lavergne', 'Shelbyville', 'Pegram',\n",
       "       'Mt Juliet', 'Manchester', 'Whites Creek', 'Silver Point',\n",
       "       'Ashland City'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view a unique list of cities in the dataframe\n",
    "final_clean['city_oct2023'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f45474f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nashville' 'Brentwood' 'Murfreesboro' 'Hendersonville' 'Franklin'\n",
      " 'Smyrna' 'Goodlettsville' 'Hermitage' 'Antioch' 'Mt. Juliet' 'La Vergne'\n",
      " 'Mount Juliet' 'Forest Hills' 'Nolensville' 'Arrington' 'Lavergne'\n",
      " 'Mt Juliet' 'Whites Creek']\n"
     ]
    }
   ],
   "source": [
    "#Create a list of cities to keep in the dataset\n",
    "cities_to_keep = ['Nashville', \n",
    "                  'Brentwood', \n",
    "                  'Murfreesboro',\n",
    "                  'Hendersonville', \n",
    "                  'Franklin', \n",
    "                  'Smyrna', \n",
    "                  'Goodlettsville',\n",
    "                  'Hermitage', \n",
    "                  'Antioch', \n",
    "                  'Mt. Juliet',\n",
    "                  'La Vergne', \n",
    "                  'Mount Juliet', \n",
    "                  'Forest Hills', \n",
    "                  'Nolensville', \n",
    "                  'Arrington', \n",
    "                  'Lavergne',\n",
    "                  'Mt Juliet', \n",
    "                  'Whites Creek']\n",
    "\n",
    "#Filter for only the cities of interest\n",
    "final_clean = final_clean[final_clean['city_oct2023'].isin(cities_to_keep)]\n",
    "\n",
    "# view a unique list of the new city names\n",
    "print(final_clean['city_oct2023'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d7e9650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nashville', 'Brentwood', 'Murfreesboro', 'Hendersonville',\n",
       "       'Franklin', 'Smyrna', 'Goodlettsville', 'Mount Juliet',\n",
       "       'La Vergne', 'Nolensville', 'Arrington'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dictionary with new names\n",
    "value_mapping = {'Mt. Juliet':'Mount Juliet',\n",
    "                 'Mt Juliet':'Mount Juliet',\n",
    "                 'Forest Hills':'Nashville',\n",
    "                 'Antioch':'Nashville',\n",
    "                 'Whites Creek':'Nashville',\n",
    "                 'Hermitage':'Nashville',\n",
    "                 'Lavergne':'La Vergne'}\n",
    "\n",
    "#Apply the new names to the city column\n",
    "final_clean.loc[final_clean['city_oct2023'].isin(value_mapping.keys()), 'city_oct2023'] = final_clean['city_oct2023'].replace(value_mapping)\n",
    "\n",
    "# view a unique list of the new city names\n",
    "final_clean['city_oct2023'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031aeea7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The file is now clean and ready for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c542d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean data\n",
    "final_clean.to_excel(r\"D:\\Data Scraping\\Turo\\Nashville\\Octorber\\Clean Data\\clean_data.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
